{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bite7cea40d344342a09e3a12f2e4b8d6f2",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision \n",
    "torch.__version__\n",
    "print(torch.cuda.current_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')\n",
    "\n",
    "'''\n",
    "image_path = '/home/medathati/Work/SpectralSelfSupervision/Data/ILSVRC/Data/CLS-LOC/train/n03944341/n03944341_7353.JPEG'\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "img1  = torchvision.transform(img)\n",
    "'''\n",
    "\n",
    "\n",
    "I  = torch.rand(5,3,5,5,device=cuda)\n",
    "I_fft = torch.rfft(I, signal_ndim=2, onesided = False, normalized=False)\n",
    "I_mag = ((I_fft[:,:,:,:,0]**2+I_fft[:,:,:,:,1]**2)**0.5)\n",
    "\n",
    "I_mag_nth = I_mag**(1-0.1)\n",
    "I_fft[:,:,:,:,0] = I_fft[:,:,:,:,0]/I_mag_nth\n",
    "I_fft[:,:,:,:,1] = I_fft[:,:,:,:,1]/I_mag_nth\n",
    "# batch x channels x height x width\n",
    "\n",
    "I_fft[I_fft!=I_fft]=0\n",
    "I_hat = torch.irfft(I_fft, signal_ndim=2, onesided = False, normalized=False)\n",
    "\n",
    "print(\"Shape of input tensor: \",I.shape)\n",
    "print(\"Shape of the FFT output: \",I_fft.shape)\n",
    "print(\"Shape of the root filter output: \",I_hat.shape)\n",
    "\n",
    "print(I)\n",
    "print(\"---I_ht---\")\n",
    "print(I_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([0.0,1.5,2.0,3.0],device=cuda)\n",
    "b = torch.tensor([0.0,.75,1.0,1.5],device=cuda)\n",
    "c = b/a\n",
    "c[c!=c]=0\n",
    "\n",
    "print(a**2)\n",
    "print(a**1)\n",
    "print(b/a)\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "I  = torch.rand(3,3,device=cuda)\n",
    "I1 = torch.min(I, dim=0,keepdim=True)\n",
    "print(I)\n",
    "print(I1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScalerVectorized(object):\n",
    "    \"\"\"MinMax Scaler\n",
    "\n",
    "    Transforms each channel to the range [a, b].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_range : tuple\n",
    "        Desired range of transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"Fit features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stacked_features : tuple, list\n",
    "            List of stacked features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tensor \n",
    "            A tensor with scaled features using requested preprocessor.\n",
    "        \"\"\"\n",
    "\n",
    "        tensor = torch.stack(tensor)\n",
    "\n",
    "        # Feature range\n",
    "        a, b = self.feature_range\n",
    "\n",
    "        dist = tensor.max(dim=0, keepdim=True)[0] - tensor.min(dim=0, keepdim=True)[0]\n",
    "        dist[dist == 0.0] = 1.0\n",
    "        scale = 1.0 / dist\n",
    "        tensor.mul_(scale).sub_(tensor.min(dim=0, keepdim=True)[0])\n",
    "        tensor.mul_(b - a).add_(a)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "scaler = MinMaxScalerVectorized(feature_range=(-1, 1))\n",
    "I2 = scaler(I)\n",
    "print(I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[[ 0.7264,  1.3371,  0.1607],\n         [ 0.0646,  0.6287, -0.8154],\n         [-0.3210, -0.1670,  0.7265]],\n\n        [[ 0.4167, -0.7599, -0.4026],\n         [ 1.5075,  1.9788,  0.6498],\n         [-0.0632, -0.5583,  0.6603]],\n\n        [[-0.5028,  0.7215, -2.0491],\n         [-0.3033, -1.5699, -0.1638],\n         [-1.5514, -1.5809,  0.4457]]])\ntensor([[[0.7163, 1.0000, 0.4535],\n         [0.4088, 0.6709, 0.0000],\n         [0.2297, 0.3013, 0.7163]],\n\n        [[0.4296, 0.0000, 0.1305],\n         [0.8279, 1.0000, 0.5147],\n         [0.2544, 0.0736, 0.5186]],\n\n        [[0.5581, 1.0000, 0.0000],\n         [0.6301, 0.1730, 0.6805],\n         [0.1796, 0.1690, 0.9004]]])\n"
    }
   ],
   "source": [
    "#a = torch.randn(3, 4, 16, 16, 16, 16)\n",
    "a = torch.randn(3, 3,3)\n",
    "\n",
    "def MinMaxNormalize(X):\n",
    "    X_channel_flat = X.view(*(X.size()[:-2]),1,-1)\n",
    "    X_channel_min,_ = torch.min(X_channel_flat,len(X.size())-1, keepdim=True, out=None)\n",
    "    X_channel_max,_ = torch.max(X_channel_flat,len(X.size())-1, keepdim=True, out=None)\n",
    "    X_channel_den = X_channel_max - X_channel_min\n",
    "    X_channel_den[X_channel_den==0] = 1.0 # To avoid division by zero\n",
    "    X_normalized_flat = (X_channel_flat - X_channel_min)/X_channel_den\n",
    "    X_normalized = X_normalized_flat.view(X.size())\n",
    "    return X_normalized\n",
    "\n",
    "print(a)\n",
    "print(MinMaxNormalize(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}